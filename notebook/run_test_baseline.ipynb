{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28987cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa26d82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# htmlの文字化けを解消したい。\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import chardet\n",
    "\n",
    "def normalize_html_content(content):\n",
    "    # bytesならエンコーディング推定→デコード\n",
    "    if isinstance(content, (bytes, bytearray)):\n",
    "        enc = chardet.detect(content).get(\"encoding\") or \"utf-8\"\n",
    "        text = content.decode(enc, errors=\"replace\")\n",
    "    else:\n",
    "        text = content\n",
    "\n",
    "    # <meta charset=\"utf-8\"> を保証\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    if soup.head is None:\n",
    "        # head がない場合は作る\n",
    "        html = soup.new_tag(\"html\")\n",
    "        head = soup.new_tag(\"head\")\n",
    "        body = soup.new_tag(\"body\")\n",
    "        body.append(soup)  # 既存ノードを body 下へ\n",
    "        html.append(head)\n",
    "        html.append(body)\n",
    "        soup = BeautifulSoup(str(html), \"html.parser\")\n",
    "\n",
    "    if not soup.head.find(\"meta\", attrs={\"charset\": True}):\n",
    "        meta = soup.new_tag(\"meta\", charset=\"utf-8\")\n",
    "        soup.head.insert(0, meta)\n",
    "    else:\n",
    "        soup.head.find(\"meta\", attrs={\"charset\": True})[\"charset\"] = \"utf-8\"\n",
    "\n",
    "    # テーブルの線を表示するためのCSSスタイルを追加\n",
    "    style = soup.new_tag(\"style\")\n",
    "    style.string = \"\"\"\n",
    "    table {\n",
    "        border-collapse: collapse;\n",
    "        width: 100%;\n",
    "        margin: 10px 0;\n",
    "    }\n",
    "    table, th, td {\n",
    "        border: 1px solid #000;\n",
    "    }\n",
    "    th, td {\n",
    "        padding: 8px;\n",
    "        text-align: left;\n",
    "    }\n",
    "    th {\n",
    "        background-color: #f2f2f2;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    \"\"\"\n",
    "    soup.head.append(style)\n",
    "\n",
    "    return str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4e34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(html, pdf_path, output_dir):\n",
    "    output_path = output_dir / pdf_path.with_suffix(\".html\").name\n",
    "    html = normalize_html_content(html)\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "def save_markdown(markdown, pdf_path, output_dir):\n",
    "    output_path = output_dir / pdf_path.with_suffix(\".md\").name\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429415c9",
   "metadata": {},
   "source": [
    "## Upstage/Document Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1be5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_upstage(pdf_path, output_dir: Path = Path(\"../output/upstage\"), type: str = \"html\", save: bool = True):\n",
    "    url = \"https://api.upstage.ai/v1/document-digitization\"\n",
    "    api_key = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    # extracted_pdf_pathを使用（前のセルで設定された一時PDFファイル）\n",
    "    files = {\"document\": open(pdf_path, \"rb\")}\n",
    "    data = {\"ocr\": \"auto\", \"model\": \"document-parse-nightly\"}\n",
    "    response = requests.post(url, headers=headers, files=files, data=data)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error: {response.status_code} - {response.text}\")\n",
    "    if type == \"html\":\n",
    "        content = response.json()[\"content\"][\"html\"]\n",
    "    elif type == \"markdown\":\n",
    "        content = response.json()[\"content\"][\"markdown\"]\n",
    "    if save:\n",
    "        output_path = output_dir / pdf_path.parent.name\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        if type == \"html\":\n",
    "            save_html(content, pdf_path, output_path)\n",
    "        elif type == \"markdown\":\n",
    "            save_markdown(content, pdf_path, output_path)\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1516d2e",
   "metadata": {},
   "source": [
    "## Azure Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "366cca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult, AnalyzeDocumentRequest, DocumentContentFormat\n",
    "\n",
    "client = DocumentIntelligenceClient(\n",
    "            endpoint=os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\"),\n",
    "            credential=AzureKeyCredential(os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\"))\n",
    "        )\n",
    "\n",
    "def run_azure_di(pdf_path, output_dir: Path = Path(\"../output/azure\"), save: bool = True):\n",
    "    with pdf_path.open(\"rb\") as file:\n",
    "        poller = client.begin_analyze_document(\n",
    "            model_id=\"prebuilt-layout\",\n",
    "            body=file,\n",
    "            output_content_format=DocumentContentFormat.MARKDOWN\n",
    "        )\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    if save:\n",
    "        output_path = output_dir / pdf_path.parent.name\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        save_markdown(result.content, pdf_path, output_path)\n",
    "    return result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d808d9af",
   "metadata": {},
   "source": [
    "## YOMITOKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cefa3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import nest_asyncio\n",
    "\n",
    "from yomitoku import DocumentAnalyzer\n",
    "from yomitoku.data.functions import load_pdf, load_image\n",
    "\n",
    "# Jupyter環境でasyncioを使用するための設定\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "\n",
    "def run_yomitoku(pdf_path: Path, output_dir: Path = Path(\"../output/yomitoku\"), save: bool = True):\n",
    "\n",
    "    analyzer = DocumentAnalyzer(visualize=True, device=\"cpu\")\n",
    "\n",
    "    # PDFファイルを読み込み\n",
    "\n",
    "    imgs = load_pdf(pdf_path)\n",
    "    output_results = []\n",
    "    for i, img in enumerate(imgs):\n",
    "\n",
    "        results, ocr_vis, layout_vis = analyzer(img)\n",
    "\n",
    "        # HTML形式で解析結果をエクスポート\n",
    "        parent_path = output_dir / pdf_path.parent.name \n",
    "        parent_path.mkdir(parents=True, exist_ok=True)\n",
    "        output_path = parent_path / (pdf_path.name.split(\".\")[0] + f\"_{i}.html\")\n",
    "        results.to_html(str(output_path), img=img)\n",
    "        output_results.append(results)\n",
    "        # 可視化画像を保存\n",
    "        output_ocr_path = parent_path / (pdf_path.name.split(\".\")[0] + f\"_ocr_{i}.jpg\")\n",
    "        cv2.imwrite(str(output_ocr_path), ocr_vis)\n",
    "        output_layout_path = parent_path / (pdf_path.name.split(\".\")[0] + f\"_layout_{i}.jpg\")\n",
    "        cv2.imwrite(str(output_layout_path), layout_vis)\n",
    "    return output_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba294e98",
   "metadata": {},
   "source": [
    "## Gemini 2.5 flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c430c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "import io\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "def run_gemini(pdf_path: Path, output_dir: Path = Path(\"../output/gemini\"), save: bool = True):\n",
    "    # 全ページを画像に変換\n",
    "    images = convert_from_path(pdf_path, dpi=200)\n",
    "    \n",
    "    client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "    \n",
    "    PROMPT = \"\"\"\n",
    "    これは PDF ドキュメントのページです。構造を維持しながら、すべてのテキストコンテンツを抽出してください。\n",
    "    テーブル、列、見出し、および構造化されたコンテンツに特に注意を払ってください。\n",
    "\n",
    "    テーブルの場合：\n",
    "    1. マークダウンテーブル形式を使用してテーブル構造を維持\n",
    "    2. すべての列ヘッダーと行ラベルを保持\n",
    "    3. 数値データが正確にキャプチャされていることを確認\n",
    "\n",
    "    マルチカラムレイアウトの場合：\n",
    "    1. 左から右へ列を処理\n",
    "    2. 異なる列のコンテンツを明確に区別\n",
    "\n",
    "    チャートやグラフの場合：\n",
    "    1. チャートのタイプを説明\n",
    "    2. 可視の軸ラベル、凡例、データポイントを抽出\n",
    "    3. タイトルやキャプションを抽出\n",
    "\n",
    "    イラストの場合：\n",
    "    1. イラストのタイトルを抽出\n",
    "    2. イラストの内容を説明\n",
    "\n",
    "    段落の区切りと書式を維持してください。\n",
    "    すべての見出し、フッター、ページ番号、脚注を維持してください。\n",
    "\n",
    "    出力は必ずマークダウン形式で行って下さい。\n",
    "    \"\"\"\n",
    "    \n",
    "    # 各ページを処理して結果を格納\n",
    "    page_outputs = []\n",
    "    \n",
    "    for i, image in enumerate(images):\n",
    "        # 画像をバイト形式に変換\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        image.save(img_byte_arr, format='JPEG')\n",
    "        image_bytes = img_byte_arr.getvalue()\n",
    "        \n",
    "        # 各ページを個別に処理\n",
    "        response = client.models.generate_content(\n",
    "            model='gemini-2.5-flash',\n",
    "            contents=[\n",
    "                types.Part.from_bytes(\n",
    "                    data=image_bytes,\n",
    "                    mime_type='image/jpeg',\n",
    "                ),\n",
    "                PROMPT + f\"\\n\\n（これはページ {i+1}/{len(images)} です）\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        page_outputs.append(f\"<!-- ページ {i+1} -->\\n{response.text}\")\n",
    "    \n",
    "    # 全ページの結果を結合\n",
    "    output = \"\\n\\n---\\n\\n\".join(page_outputs)\n",
    "    \n",
    "    if save:\n",
    "        output_path = output_dir / pdf_path.parent.name\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        save_markdown(output, pdf_path, output_path)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23294cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def measure_time(func, *args, **kwargs):\n",
    "    \"\"\"関数の実行時間を計測するデコレータ\"\"\"\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    return result, execution_time\n",
    "\n",
    "def save_timing_results(timing_data, output_dir=\"timing_results\"):\n",
    "    \"\"\"タイミング結果をJSONファイルに保存\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"timing_results_{timestamp}.json\"\n",
    "    filepath = output_path / filename\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(timing_data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"タイミング結果を保存しました: {filepath}\")\n",
    "    return filepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcb83478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoTokenizer, AutoProcessor, AutoModelForImageTextToText\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import torch\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# モデルキャッシュ用のグローバル変数\n",
    "_models_cache = {}\n",
    "\n",
    "def download_models():\n",
    "    \"\"\"Qwen2.5VLとQwen3VLのモデルを事前にダウンロードしてキャッシュする\"\"\"\n",
    "    \n",
    "    print(\"Qwen2.5VLモデルをダウンロード中...\")\n",
    "    device, dtype = _select_device_and_dtype()\n",
    "    \n",
    "    # Qwen2.5VLモデルのダウンロード\n",
    "    qwen25vl_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "        \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "        dtype=dtype,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=\"auto\" if device.type != \"cpu\" else None\n",
    "    )\n",
    "    qwen25vl_processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "    \n",
    "    _models_cache['qwen25vl'] = {\n",
    "        'model': qwen25vl_model,\n",
    "        'processor': qwen25vl_processor,\n",
    "        'device': device,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    \n",
    "    print(\"Qwen3VLモデルをダウンロード中...\")\n",
    "    \n",
    "    # Qwen3VLモデルのダウンロード\n",
    "    qwen3vl_model = AutoModelForImageTextToText.from_pretrained(\n",
    "        \"Qwen/Qwen3-VL-235B-A22B-Instruct\", \n",
    "        dtype=dtype,\n",
    "        torch_dtype=dtype,\n",
    "        device_map=\"auto\" if device.type != \"cpu\" else None\n",
    "    )\n",
    "    qwen3vl_processor = AutoProcessor.from_pretrained(\"Qwen/Qwen3-VL-235B-A22B-Instruct\")\n",
    "    \n",
    "    _models_cache['qwen3vl'] = {\n",
    "        'model': qwen3vl_model,\n",
    "        'processor': qwen3vl_processor,\n",
    "        'device': device,\n",
    "        'dtype': dtype\n",
    "    }\n",
    "    \n",
    "    print(\"モデルのダウンロードが完了しました！\")\n",
    "\n",
    "def _select_device_and_dtype():\n",
    "    \"\"\"デバイスとデータ型を選択する\"\"\"\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "        dtype = torch.float16\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        dtype = torch.float16\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        dtype = torch.float32\n",
    "    return device, dtype\n",
    "\n",
    "## Qwen2.5-VL/Qwen3-VL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3994ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共通のプロンプトを定義\n",
    "PROMPT = \"\"\"\n",
    "これは PDF ドキュメントのページです。構造を維持しながら、すべてのテキストコンテンツを抽出してください。\n",
    "テーブル、列、見出し、および構造化されたコンテンツに特に注意を払ってください。\n",
    "\n",
    "テーブルの場合：\n",
    "1. マークダウンテーブル形式を使用してテーブル構造を維持\n",
    "2. すべての列ヘッダーと行ラベルを保持\n",
    "3. 数値データが正確にキャプチャされていることを確認\n",
    "\n",
    "マルチカラムレイアウトの場合：\n",
    "1. 左から右へ列を処理\n",
    "2. 異なる列のコンテンツを明確に区別\n",
    "\n",
    "チャートやグラフの場合：\n",
    "1. チャートのタイプを説明\n",
    "2. 可視の軸ラベル、凡例、データポイントを抽出\n",
    "3. タイトルやキャプションを抽出\n",
    "\n",
    "イラストの場合：\n",
    "1. イラストのタイトルを抽出\n",
    "2. イラストの内容を説明\n",
    "\n",
    "段落の区切りと書式を維持してください。\n",
    "すべての見出し、フッター、ページ番号、脚注を維持してください。\n",
    "\n",
    "出力は必ずマークダウン形式で行って下さい。\n",
    "\"\"\"\n",
    "\n",
    "def process_single_page_qwen(model_info, image, page_num, total_pages, prompt=PROMPT):\n",
    "    \"\"\"単一ページを処理する共通関数（最適化済み）\"\"\"\n",
    "\n",
    "    model = model_info['model']\n",
    "    processor = model_info['processor']\n",
    "    device = model_info['device']\n",
    "    \n",
    "    # メッセージを構築\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": image},\n",
    "                {\"type\": \"text\", \"text\": prompt + f\"\\n\\n（これはページ {page_num + 1}/{total_pages} です）\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # プロンプトの準備\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "    \n",
    "    # バッチ処理用の入力準備\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {k: v.to(device) if hasattr(v, \"to\") else v for k, v in inputs.items()}\n",
    "\n",
    "    # 推論実行（最適化されたパラメータ）\n",
    "    with torch.no_grad():  # メモリ使用量を削減\n",
    "        generated_ids = model.generate(\n",
    "            **inputs, \n",
    "            max_new_tokens=2048,\n",
    "            do_sample=False,  # 確定的な出力\n",
    "            temperature=0.1,  # 低い温度で一貫性を向上\n",
    "            pad_token_id=processor.tokenizer.eos_token_id,\n",
    "            use_cache=True  # KVキャッシュを使用\n",
    "        )\n",
    "    \n",
    "    generated_ids_trimmed = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs[\"input_ids\"], generated_ids)]\n",
    "    output_text = processor.batch_decode(generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "    \n",
    "    return f\"<!-- ページ {page_num + 1} -->\\n{output_text[0]}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79cbee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_qwen25vl_optimized(pdf_path, output_dir=None, save=False):\n",
    "    \"\"\"\n",
    "    Qwen2.5-VLを使用してPDFからテキストを抽出する関数（最適化版）\n",
    "    事前にダウンロードされたモデルを使用\n",
    "    \"\"\"\n",
    "   \n",
    "    # モデルがダウンロードされていない場合はダウンロード\n",
    "    if 'qwen25vl' not in _models_cache:\n",
    "        print(\"Qwen2.5VLモデルがダウンロードされていません。ダウンロードを開始します...\")\n",
    "        download_models()\n",
    "    \n",
    "    model_info = _models_cache['qwen25vl']\n",
    "    \n",
    "    # PDFを開く\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_pages = len(doc)\n",
    "    \n",
    "    # 各ページを個別に処理\n",
    "    page_outputs = []\n",
    "    \n",
    "    for page_num in range(total_pages):\n",
    "        page = doc[page_num]\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2倍解像度\n",
    "        img_data = pix.tobytes(\"png\")\n",
    "        image = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        # 最適化されたページ処理\n",
    "        page_output = process_single_page_qwen(model_info, image, page_num, total_pages)\n",
    "        page_outputs.append(page_output)\n",
    "    \n",
    "    # 全ページの結果を結合\n",
    "    response_content = \"\\n\\n---\\n\\n\".join(page_outputs)\n",
    "\n",
    "    if save and output_dir is not None:\n",
    "        output_path = output_dir / pdf_path.parent.name\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        save_markdown(response_content, pdf_path, output_path)\n",
    "\n",
    "    doc.close()\n",
    "    return response_content\n",
    "\n",
    "def run_qwen3vl_optimized(pdf_path, output_dir=None, save=False):\n",
    "    \"\"\"\n",
    "    Qwen3-VLを使用してPDFを処理する関数（最適化版）\n",
    "    事前にダウンロードされたモデルを使用\n",
    "    \"\"\"\n",
    "    import fitz  # PyMuPDF\n",
    "    from PIL import Image\n",
    "    import io\n",
    "    \n",
    "    # モデルがダウンロードされていない場合はダウンロード\n",
    "    if 'qwen3vl' not in _models_cache:\n",
    "        print(\"Qwen3VLモデルがダウンロードされていません。ダウンロードを開始します...\")\n",
    "        download_models()\n",
    "    \n",
    "    model_info = _models_cache['qwen3vl']\n",
    "    \n",
    "    # PDFを開く\n",
    "    doc = fitz.open(pdf_path)\n",
    "    total_pages = len(doc)\n",
    "\n",
    "    # 各ページを個別に処理\n",
    "    page_outputs = []\n",
    "    \n",
    "    for page_num in range(total_pages):\n",
    "        page = doc.load_page(page_num)\n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2倍解像度\n",
    "        img_data = pix.tobytes(\"png\")\n",
    "        image = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        # 最適化されたページ処理\n",
    "        page_output = process_single_page_qwen(model_info, image, page_num, total_pages)\n",
    "        page_outputs.append(page_output)\n",
    "    \n",
    "    # 全ページの結果を結合\n",
    "    response_content = \"\\n\\n---\\n\\n\".join(page_outputs)\n",
    "\n",
    "    if save and output_dir is not None:\n",
    "        output_path = output_dir / pdf_path.parent.name\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        save_markdown(response_content, pdf_path, output_path)\n",
    "\n",
    "    doc.close()\n",
    "    return response_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e3d3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用方法の例\n",
    "def initialize_models():\n",
    "    \"\"\"モデルを初期化する関数（最初に1回だけ実行）\"\"\"\n",
    "    print(\"モデルを初期化中...\")\n",
    "    download_models()\n",
    "    print(\"初期化完了！\")\n",
    "\n",
    "def clear_model_cache():\n",
    "    \"\"\"モデルキャッシュをクリアする関数（メモリ不足時など）\"\"\"\n",
    "    global _models_cache\n",
    "    _models_cache.clear()\n",
    "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "    print(\"モデルキャッシュをクリアしました\")\n",
    "\n",
    "# 実行速度向上のための追加の最適化関数\n",
    "def optimize_for_speed():\n",
    "    \"\"\"実行速度向上のための設定\"\"\"\n",
    "    \n",
    "    # PyTorchの最適化設定\n",
    "    torch.backends.cudnn.benchmark = True  # CUDA最適化\n",
    "    torch.backends.cudnn.deterministic = False  # 速度優先\n",
    "    \n",
    "    # メモリ効率化\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"速度最適化設定を適用しました\")\n",
    "\n",
    "def get_model_info():\n",
    "    \"\"\"現在のモデルキャッシュの状態を確認\"\"\"\n",
    "    print(\"=== モデルキャッシュ状態 ===\")\n",
    "    for model_name, info in _models_cache.items():\n",
    "        print(f\"{model_name}: 読み込み済み\")\n",
    "        print(f\"  デバイス: {info['device']}\")\n",
    "        print(f\"  データ型: {info['dtype']}\")\n",
    "    if not _models_cache:\n",
    "        print(\"モデルは読み込まれていません\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a17497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_timing_summary(timing_data):\n",
    "    \"\"\"タイミング結果のサマリーを表示\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"実行時間サマリー\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 各モデルの平均実行時間を計算\n",
    "    model_stats = {}\n",
    "    \n",
    "    for result in timing_data[\"results\"]:\n",
    "        for model_name, model_data in result[\"models\"].items():\n",
    "            if model_name not in model_stats:\n",
    "                model_stats[model_name] = {\n",
    "                    \"total_time\": 0,\n",
    "                    \"success_count\": 0,\n",
    "                    \"error_count\": 0,\n",
    "                    \"times\": []\n",
    "                }\n",
    "            \n",
    "            if model_data[\"status\"] == \"success\":\n",
    "                model_stats[model_name][\"total_time\"] += model_data[\"execution_time\"]\n",
    "                model_stats[model_name][\"success_count\"] += 1\n",
    "                model_stats[model_name][\"times\"].append(model_data[\"execution_time\"])\n",
    "            else:\n",
    "                model_stats[model_name][\"error_count\"] += 1\n",
    "    \n",
    "    # 結果を表示\n",
    "    for model_name, stats in model_stats.items():\n",
    "        print(f\"\\n{model_name}:\")\n",
    "        print(f\"  成功: {stats['success_count']} ファイル\")\n",
    "        print(f\"  エラー: {stats['error_count']} ファイル\")\n",
    "        \n",
    "        if stats[\"success_count\"] > 0:\n",
    "            avg_time = stats[\"total_time\"] / stats[\"success_count\"]\n",
    "            min_time = min(stats[\"times\"])\n",
    "            max_time = max(stats[\"times\"])\n",
    "            print(f\"  平均実行時間: {avg_time:.2f} 秒\")\n",
    "            print(f\"  最短実行時間: {min_time:.2f} 秒\")\n",
    "            print(f\"  最長実行時間: {max_time:.2f} 秒\")\n",
    "            print(f\"  総実行時間: {stats['total_time']:.2f} 秒\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07214827",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(file_list:list[Path]):\n",
    "    for file_path in file_list:\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        run_upstage(file_path, output_dir=Path(\"../output/upstage\"), save=True)\n",
    "        print(\"Processing Upstage/Document Parse... done\")\n",
    "        run_azure_di(file_path, output_dir=Path(\"../output/azure\"), save=True)\n",
    "        print(\"Processing Azure/Document Intelligence... done\")\n",
    "        run_yomitoku(file_path, output_dir=Path(\"../output/yomitoku\"), save=True)\n",
    "        print(\"Processing YOMITOKU... done\")\n",
    "        run_gemini(file_path, output_dir=Path(\"../output/gemini\"), save=True)\n",
    "        print(\"Processing Gemini 2.5 Flash... done\")\n",
    "\n",
    "def run_qwen(file_list:list[Path]):\n",
    "    initialize_models()\n",
    "    for file_path in file_list:\n",
    "        run_qwen25vl_optimized(file_path, output_dir=Path(\"../output/qwen25vl\"), save=True)\n",
    "        run_qwen3vl_optimized(file_path, output_dir=Path(\"../output/qwen3vl\"), save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec47a45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerateエラーを修正したdownload_models関数\n",
    "def download_models_fixed():\n",
    "    \"\"\"Qwen2.5VLとQwen3VLのモデルを事前にダウンロードしてキャッシュする（accelerateエラー修正版）\"\"\"\n",
    "    import torch\n",
    "    \n",
    "    print(\"Qwen2.5VLモデルをダウンロード中...\")\n",
    "    device, dtype = _select_device_and_dtype()\n",
    "    \n",
    "    # accelerateが利用可能かチェック\n",
    "    try:\n",
    "        import accelerate\n",
    "        use_device_map = True\n",
    "        print(\"accelerateが利用可能です。device_mapを使用します。\")\n",
    "    except ImportError:\n",
    "        use_device_map = False\n",
    "        print(\"accelerateが利用できません。device_mapを使用せずにモデルを読み込みます。\")\n",
    "    \n",
    "    # Qwen2.5VLモデルのダウンロード\n",
    "    try:\n",
    "        if use_device_map and device.type != \"cpu\":\n",
    "            qwen25vl_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "                \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "                dtype=dtype,\n",
    "                device_map=\"auto\"\n",
    "            )\n",
    "        else:\n",
    "            qwen25vl_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "                \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "                dtype=dtype\n",
    "            )\n",
    "            qwen25vl_model = qwen25vl_model.to(device)\n",
    "        \n",
    "        qwen25vl_processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\n",
    "        \n",
    "        _models_cache['qwen25vl'] = {\n",
    "            'model': qwen25vl_model,\n",
    "            'processor': qwen25vl_processor,\n",
    "            'device': device,\n",
    "            'dtype': dtype\n",
    "        }\n",
    "        print(\"Qwen2.5VLモデルのダウンロード完了\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Qwen2.5VLモデルのダウンロードに失敗しました: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"Qwen3VLモデルをダウンロード中...\")\n",
    "    \n",
    "    # Qwen3VLモデルのダウンロード\n",
    "    # try:\n",
    "    #     if use_device_map and device.type != \"cpu\":\n",
    "    #         qwen3vl_model = AutoModelForImageTextToText.from_pretrained(\n",
    "    #             \"Qwen/Qwen3-VL-235B-A22B-Instruct\", \n",
    "    #             torch_dtype=dtype,\n",
    "    #             device_map=\"auto\"\n",
    "    #         )\n",
    "    #     else:\n",
    "    #         qwen3vl_model = AutoModelForImageTextToText.from_pretrained(\n",
    "    #             \"Qwen/Qwen3-VL-235B-A22B-Instruct\", \n",
    "    #             torch_dtype=dtype\n",
    "    #         )\n",
    "    #         qwen3vl_model = qwen3vl_model.to(device)\n",
    "        \n",
    "    #     qwen3vl_processor = AutoProcessor.from_pretrained(\"Qwen/Qwen3-VL-235B-A22B-Instruct\")\n",
    "        \n",
    "    #     _models_cache['qwen3vl'] = {\n",
    "    #         'model': qwen3vl_model,\n",
    "    #         'processor': qwen3vl_processor,\n",
    "    #         'device': device,\n",
    "    #         'dtype': dtype\n",
    "    #     }\n",
    "    #     print(\"Qwen3VLモデルのダウンロード完了\")\n",
    "        \n",
    "    # except Exception as e:\n",
    "    #     print(f\"Qwen3VLモデルのダウンロードに失敗しました: {e}\")\n",
    "    #     raise\n",
    "    \n",
    "    print(\"モデルのダウンロードが完了しました！\")\n",
    "\n",
    "# 修正版のinitialize_models関数\n",
    "def initialize_models_fixed():\n",
    "    \"\"\"モデルを初期化する関数（最初に1回だけ実行）- accelerateエラー修正版\"\"\"\n",
    "    print(\"モデルを初期化中...\")\n",
    "    download_models_fixed()\n",
    "    print(\"初期化完了！\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed1254fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修正版のrun_qwen関数\n",
    "def run_qwen_fixed(file_list:list[Path]):\n",
    "    \"\"\"Qwenモデル処理を実行（accelerateエラー修正版）\"\"\"\n",
    "    initialize_models_fixed()\n",
    "    for file_path in file_list:\n",
    "        print(f\"Processing {file_path}...\")\n",
    "        run_qwen25vl_optimized(file_path, output_dir=Path(\"../output/qwen25vl\"), save=True)\n",
    "        run_qwen3vl_optimized(file_path, output_dir=Path(\"../output/qwen3vl\"), save=True)\n",
    "\n",
    "# 修正版のrun_qwen_timed関数\n",
    "def run_qwen_timed_fixed(file_list:list[Path]):\n",
    "    \"\"\"Qwenモデル処理を実行し、各モデルの計算時間を計測（accelerateエラー修正版）\"\"\"\n",
    "    timing_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_files\": len(file_list),\n",
    "        \"results\": []\n",
    "    }\n",
    "    \n",
    "    # モデルを初期化\n",
    "    print(\"モデルを初期化中...\")\n",
    "    initialize_models_fixed()\n",
    "    \n",
    "    for file_idx, file_path in enumerate(file_list):\n",
    "        print(f\"Processing {file_path}... ({file_idx + 1}/{len(file_list)})\")\n",
    "        \n",
    "        file_result = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"file_name\": file_path.name,\n",
    "            \"models\": {}\n",
    "        }\n",
    "        \n",
    "        # Qwen2.5VL\n",
    "        print(\"  Processing Qwen2.5VL...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_qwen25vl_optimized, file_path, output_dir=Path(\"../output/qwen25vl\"), save=True)\n",
    "            file_result[\"models\"][\"qwen25vl\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Qwen2.5VL completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"qwen25vl\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Qwen2.5VL failed: {e}\")\n",
    "        \n",
    "        # Qwen3VL\n",
    "        print(\"  Processing Qwen3VL...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_qwen3vl_optimized, file_path, output_dir=Path(\"../output/qwen3vl\"), save=True)\n",
    "            file_result[\"models\"][\"qwen3vl\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Qwen3VL completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"qwen3vl\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Qwen3VL failed: {e}\")\n",
    "        \n",
    "        timing_data[\"results\"].append(file_result)\n",
    "        print(f\"  File {file_idx + 1} completed\\n\")\n",
    "    \n",
    "    # タイミング結果を保存\n",
    "    save_timing_results(timing_data, \"timing_results_qwen\")\n",
    "    \n",
    "    # サマリーを表示\n",
    "    print_timing_summary(timing_data)\n",
    "    \n",
    "    return timing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9b66e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日時ベースの出力フォルダ構造に対応した修正版関数\n",
    "\n",
    "def run_baseline_timed_with_datetime(file_list:list[Path]):\n",
    "    \"\"\"ベースライン処理を実行し、各モデルの計算時間を計測（日時フォルダ対応版）\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # 日時ベースの出力フォルダを作成\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    base_output_dir = Path(f\"../output/{timestamp}\")\n",
    "    base_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    timing_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_files\": len(file_list),\n",
    "        \"output_base_dir\": str(base_output_dir),\n",
    "        \"results\": []\n",
    "    }\n",
    "    \n",
    "    for file_idx, file_path in enumerate(file_list):\n",
    "        print(f\"Processing {file_path}... ({file_idx + 1}/{len(file_list)})\")\n",
    "        \n",
    "        file_result = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"file_name\": file_path.name,\n",
    "            \"models\": {}\n",
    "        }\n",
    "        \n",
    "        # Upstage/Document Parse\n",
    "        print(\"  Processing Upstage/Document Parse...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_upstage, file_path, output_dir=base_output_dir / \"upstage\", save=True)\n",
    "            file_result[\"models\"][\"upstage\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Upstage completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"upstage\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Upstage failed: {e}\")\n",
    "        \n",
    "        # Azure Document Intelligence\n",
    "        print(\"  Processing Azure/Document Intelligence...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_azure_di, file_path, output_dir=base_output_dir / \"azure\", save=True)\n",
    "            file_result[\"models\"][\"azure\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Azure completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"azure\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Azure failed: {e}\")\n",
    "        \n",
    "        # YOMITOKU\n",
    "        print(\"  Processing YOMITOKU...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_yomitoku, file_path, output_dir=base_output_dir / \"yomitoku\", save=True)\n",
    "            file_result[\"models\"][\"yomitoku\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    YOMITOKU completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"yomitoku\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    YOMITOKU failed: {e}\")\n",
    "        \n",
    "        # Gemini 2.5 Flash\n",
    "        print(\"  Processing Gemini 2.5 Flash...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_gemini, file_path, output_dir=base_output_dir / \"gemini\", save=True)\n",
    "            file_result[\"models\"][\"gemini\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Gemini completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"gemini\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Gemini failed: {e}\")\n",
    "        \n",
    "        timing_data[\"results\"].append(file_result)\n",
    "        print(f\"  File {file_idx + 1} completed\\n\")\n",
    "    \n",
    "    # タイミング結果を保存（outputフォルダ内に保存）\n",
    "    save_timing_results(timing_data, str(base_output_dir / \"timing_results\"))\n",
    "    \n",
    "    # サマリーを表示\n",
    "    print_timing_summary(timing_data)\n",
    "    \n",
    "    print(f\"\\n出力フォルダ: {base_output_dir}\")\n",
    "    return timing_data\n",
    "\n",
    "def run_qwen_timed_with_datetime(file_list:list[Path]):\n",
    "    \"\"\"Qwenモデル処理を実行し、各モデルの計算時間を計測（日時フォルダ対応版）\"\"\"\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # 日時ベースの出力フォルダを作成\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "    base_output_dir = Path(f\"../output/{timestamp}\")\n",
    "    base_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    timing_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_files\": len(file_list),\n",
    "        \"output_base_dir\": str(base_output_dir),\n",
    "        \"results\": []\n",
    "    }\n",
    "    \n",
    "    # モデルを初期化\n",
    "    print(\"モデルを初期化中...\")\n",
    "    initialize_models_fixed()\n",
    "    \n",
    "    for file_idx, file_path in enumerate(file_list):\n",
    "        print(f\"Processing {file_path}... ({file_idx + 1}/{len(file_list)})\")\n",
    "        \n",
    "        file_result = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"file_name\": file_path.name,\n",
    "            \"models\": {}\n",
    "        }\n",
    "        \n",
    "        # Qwen2.5VL\n",
    "        print(\"  Processing Qwen2.5VL...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_qwen25vl_optimized, file_path, output_dir=base_output_dir / \"qwen25vl\", save=True)\n",
    "            file_result[\"models\"][\"qwen25vl\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Qwen2.5VL completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"qwen25vl\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Qwen2.5VL failed: {e}\")\n",
    "        \n",
    "        # Qwen3VL\n",
    "        # print(\"  Processing Qwen3VL...\")\n",
    "        # try:\n",
    "        #     _, exec_time = measure_time(run_qwen3vl_optimized, file_path, output_dir=base_output_dir / \"qwen3vl\", save=True)\n",
    "        #     file_result[\"models\"][\"qwen3vl\"] = {\n",
    "        #         \"status\": \"success\",\n",
    "        #         \"execution_time\": exec_time\n",
    "        #     }\n",
    "        #     print(f\"    Qwen3VL completed in {exec_time:.2f} seconds\")\n",
    "        # except Exception as e:\n",
    "        #     file_result[\"models\"][\"qwen3vl\"] = {\n",
    "        #         \"status\": \"error\",\n",
    "        #         \"error\": str(e),\n",
    "        #         \"execution_time\": 0\n",
    "        #     }\n",
    "        #     print(f\"    Qwen3VL failed: {e}\")\n",
    "        \n",
    "        timing_data[\"results\"].append(file_result)\n",
    "        print(f\"  File {file_idx + 1} completed\\n\")\n",
    "    \n",
    "    # タイミング結果を保存（outputフォルダ内に保存）\n",
    "    save_timing_results(timing_data, str(base_output_dir / \"timing_results\"))\n",
    "    \n",
    "    # サマリーを表示\n",
    "    print_timing_summary(timing_data)\n",
    "    \n",
    "    print(f\"\\n出力フォルダ: {base_output_dir}\")\n",
    "    return timing_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "702e9da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "修正版関数の使用方法:\n",
      "==================================================\n",
      "1. ベースライン処理（日時フォルダ対応）:\n",
      "   baseline_results = run_baseline_timed_with_datetime(files_list)\n",
      "\n",
      "2. Qwenモデル処理（日時フォルダ対応）:\n",
      "   qwen_results = run_qwen_timed_with_datetime(files_list)\n",
      "\n",
      "出力フォルダ構造:\n",
      "output/\n",
      "├── 20250126-1430/          # 実行日時フォルダ\n",
      "│   ├── upstage/            # Upstage/Document Parse結果\n",
      "│   ├── azure/              # Azure Document Intelligence結果\n",
      "│   ├── yomitoku/           # YOMITOKU結果\n",
      "│   ├── gemini/             # Gemini 2.5 Flash結果\n",
      "│   ├── qwen25vl/           # Qwen2.5VL結果\n",
      "│   ├── qwen3vl/            # Qwen3VL結果\n",
      "│   └── timing_results/     # タイミング結果\n",
      "│       └── timing_results_20250126_143000.json\n",
      "└── 20250126-1500/          # 別の実行時のフォルダ\n",
      "    ├── upstage/\n",
      "    ├── azure/\n",
      "    ├── ...\n",
      "    └── timing_results/\n",
      "        └── timing_results_20250126_150000.json\n"
     ]
    }
   ],
   "source": [
    "# 使用例とフォルダ構造の説明\n",
    "print(\"修正版関数の使用方法:\")\n",
    "print(\"=\"*50)\n",
    "print(\"1. ベースライン処理（日時フォルダ対応）:\")\n",
    "print(\"   baseline_results = run_baseline_timed_with_datetime(files_list)\")\n",
    "print()\n",
    "print(\"2. Qwenモデル処理（日時フォルダ対応）:\")\n",
    "print(\"   qwen_results = run_qwen_timed_with_datetime(files_list)\")\n",
    "print()\n",
    "print(\"出力フォルダ構造:\")\n",
    "print(\"output/\")\n",
    "print(\"├── 20250126-1430/          # 実行日時フォルダ\")\n",
    "print(\"│   ├── upstage/            # Upstage/Document Parse結果\")\n",
    "print(\"│   ├── azure/              # Azure Document Intelligence結果\")\n",
    "print(\"│   ├── yomitoku/           # YOMITOKU結果\")\n",
    "print(\"│   ├── gemini/             # Gemini 2.5 Flash結果\")\n",
    "print(\"│   ├── qwen25vl/           # Qwen2.5VL結果\")\n",
    "print(\"│   ├── qwen3vl/            # Qwen3VL結果\")\n",
    "print(\"│   └── timing_results/     # タイミング結果\")\n",
    "print(\"│       └── timing_results_20250126_143000.json\")\n",
    "print(\"└── 20250126-1500/          # 別の実行時のフォルダ\")\n",
    "print(\"    ├── upstage/\")\n",
    "print(\"    ├── azure/\")\n",
    "print(\"    ├── ...\")\n",
    "print(\"    └── timing_results/\")\n",
    "print(\"        └── timing_results_20250126_150000.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97abc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しいrun_baseline関数（タイミング計測付き）\n",
    "def run_baseline_timed(file_list:list[Path]):\n",
    "    \"\"\"ベースライン処理を実行し、各モデルの計算時間を計測\"\"\"\n",
    "    timing_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_files\": len(file_list),\n",
    "        \"results\": []\n",
    "    }\n",
    "    \n",
    "    for file_idx, file_path in enumerate(file_list):\n",
    "        print(f\"Processing {file_path}... ({file_idx + 1}/{len(file_list)})\")\n",
    "        \n",
    "        file_result = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"file_name\": file_path.name,\n",
    "            \"models\": {}\n",
    "        }\n",
    "        \n",
    "        # Upstage/Document Parse\n",
    "        print(\"  Processing Upstage/Document Parse...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_upstage, file_path, output_dir=Path(\"../output/upstage\"), save=True)\n",
    "            file_result[\"models\"][\"upstage\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Upstage completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"upstage\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Upstage failed: {e}\")\n",
    "        \n",
    "        # Azure Document Intelligence\n",
    "        print(\"  Processing Azure/Document Intelligence...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_azure_di, file_path, output_dir=Path(\"../output/azure\"), save=True)\n",
    "            file_result[\"models\"][\"azure\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Azure completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"azure\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Azure failed: {e}\")\n",
    "        \n",
    "        # YOMITOKU\n",
    "        print(\"  Processing YOMITOKU...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_yomitoku, file_path, output_dir=Path(\"../output/yomitoku\"), save=True)\n",
    "            file_result[\"models\"][\"yomitoku\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    YOMITOKU completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"yomitoku\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    YOMITOKU failed: {e}\")\n",
    "        \n",
    "        # Gemini 2.5 Flash\n",
    "        print(\"  Processing Gemini 2.5 Flash...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_gemini, file_path, output_dir=Path(\"../output/gemini\"), save=True)\n",
    "            file_result[\"models\"][\"gemini\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Gemini completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"gemini\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Gemini failed: {e}\")\n",
    "        \n",
    "        timing_data[\"results\"].append(file_result)\n",
    "        print(f\"  File {file_idx + 1} completed\\n\")\n",
    "    \n",
    "    # タイミング結果を保存\n",
    "    save_timing_results(timing_data)\n",
    "    \n",
    "    # サマリーを表示\n",
    "    print_timing_summary(timing_data)\n",
    "    \n",
    "    return timing_data\n",
    "\n",
    "# 新しいrun_qwen関数（タイミング計測付き）\n",
    "def run_qwen_timed(file_list:list[Path]):\n",
    "    \"\"\"Qwenモデル処理を実行し、各モデルの計算時間を計測\"\"\"\n",
    "    timing_data = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"total_files\": len(file_list),\n",
    "        \"results\": []\n",
    "    }\n",
    "    \n",
    "    # モデルを初期化\n",
    "    print(\"モデルを初期化中...\")\n",
    "    initialize_models()\n",
    "    \n",
    "    for file_idx, file_path in enumerate(file_list):\n",
    "        print(f\"Processing {file_path}... ({file_idx + 1}/{len(file_list)})\")\n",
    "        \n",
    "        file_result = {\n",
    "            \"file_path\": str(file_path),\n",
    "            \"file_name\": file_path.name,\n",
    "            \"models\": {}\n",
    "        }\n",
    "        \n",
    "        # Qwen2.5VL\n",
    "        print(\"  Processing Qwen2.5VL...\")\n",
    "        try:\n",
    "            _, exec_time = measure_time(run_qwen25vl_optimized, file_path, output_dir=Path(\"../output/qwen25vl\"), save=True)\n",
    "            file_result[\"models\"][\"qwen25vl\"] = {\n",
    "                \"status\": \"success\",\n",
    "                \"execution_time\": exec_time\n",
    "            }\n",
    "            print(f\"    Qwen2.5VL completed in {exec_time:.2f} seconds\")\n",
    "        except Exception as e:\n",
    "            file_result[\"models\"][\"qwen25vl\"] = {\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e),\n",
    "                \"execution_time\": 0\n",
    "            }\n",
    "            print(f\"    Qwen2.5VL failed: {e}\")\n",
    "        \n",
    "        # Qwen3VL\n",
    "        # print(\"  Processing Qwen3VL...\")\n",
    "        # try:\n",
    "        #     _, exec_time = measure_time(run_qwen3vl_optimized, file_path, output_dir=Path(\"../output/qwen3vl\"), save=True)\n",
    "        #     file_result[\"models\"][\"qwen3vl\"] = {\n",
    "        #         \"status\": \"success\",\n",
    "        #         \"execution_time\": exec_time\n",
    "        #     }\n",
    "        #     print(f\"    Qwen3VL completed in {exec_time:.2f} seconds\")\n",
    "        # except Exception as e:\n",
    "        #     file_result[\"models\"][\"qwen3vl\"] = {\n",
    "        #         \"status\": \"error\",\n",
    "        #         \"error\": str(e),\n",
    "        #         \"execution_time\": 0\n",
    "        #     }\n",
    "        #     print(f\"    Qwen3VL failed: {e}\")\n",
    "        \n",
    "        timing_data[\"results\"].append(file_result)\n",
    "        print(f\"  File {file_idx + 1} completed\\n\")\n",
    "    \n",
    "    # タイミング結果を保存\n",
    "    save_timing_results(timing_data, \"timing_results_qwen\")\n",
    "    \n",
    "    # サマリーを表示\n",
    "    print_timing_summary(timing_data)\n",
    "    \n",
    "    return timing_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2047d437",
   "metadata": {},
   "source": [
    "### 最適化されたQwenモデルの使用方法\n",
    "\n",
    "#### 1. モデルの初期化（最初に1回だけ実行）\n",
    "```python\n",
    "# モデルを事前にダウンロードしてキャッシュ\n",
    "initialize_models()\n",
    "```\n",
    "\n",
    "#### 2. 最適化された関数の使用\n",
    "```python\n",
    "# 最適化されたQwen2.5VL\n",
    "content_qwen25vl = run_qwen25vl_optimized(file_path, output_dir=Path(\"../output/qwen25vl\"), save=True)\n",
    "\n",
    "# 最適化されたQwen3VL  \n",
    "content_qwen3vl = run_qwen3vl_optimized(file_path, output_dir=Path(\"../output/qwen3vl\"), save=True)\n",
    "```\n",
    "\n",
    "#### 3. その他の便利な関数\n",
    "```python\n",
    "# モデルキャッシュの状態確認\n",
    "get_model_info()\n",
    "\n",
    "# 速度最適化設定の適用\n",
    "optimize_for_speed()\n",
    "\n",
    "# メモリ不足時のキャッシュクリア\n",
    "clear_model_cache()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0fdf7e",
   "metadata": {},
   "source": [
    "## タイミング計測機能の使用方法\n",
    "\n",
    "### 1. ベースラインモデルの実行（タイミング計測付き）\n",
    "```python\n",
    "# タイミング計測付きでベースラインモデルを実行\n",
    "timing_results = run_baseline_timed(files_list)\n",
    "```\n",
    "\n",
    "### 2. Qwenモデルの実行（タイミング計測付き）\n",
    "```python\n",
    "# タイミング計測付きでQwenモデルを実行\n",
    "timing_results = run_qwen_timed(files_list)\n",
    "```\n",
    "\n",
    "### 3. 保存される情報\n",
    "- **JSONファイル**: `timing_results/` ディレクトリに保存\n",
    "- **各PDFファイルごと**:\n",
    "  - ファイル名とパス\n",
    "  - 各モデルの実行時間\n",
    "  - 成功/エラー状態\n",
    "  - エラーメッセージ（エラー時）\n",
    "- **サマリー情報**:\n",
    "  - 平均実行時間\n",
    "  - 最短/最長実行時間\n",
    "  - 成功/エラー件数\n",
    "  - 総実行時間\n",
    "\n",
    "### 4. 実行例\n",
    "```python\n",
    "# ベースラインモデルを実行\n",
    "baseline_results = run_baseline_timed(files_list[:2])  # 最初の2ファイルでテスト\n",
    "\n",
    "# Qwenモデルを実行\n",
    "qwen_results = run_qwen_timed(files_list[:2])  # 最初の2ファイルでテスト\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d73c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3deae75d",
   "metadata": {},
   "source": [
    "## 実行プロセス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15cb5118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/tables/04_要件定義書_表の中の表.pdf'),\n",
       " PosixPath('../data/tables/03_要件定義書_各種テーブル.pdf'),\n",
       " PosixPath('../data/tegaki/20250915_業務日報.pdf'),\n",
       " PosixPath('../data/tegaki/0686240_ツミタス汎用_表.pdf'),\n",
       " PosixPath('../data/tegaki/0708742_JBEC・KEC_ミライト.pdf'),\n",
       " PosixPath('../data/others/縦書き_ルビあり.pdf'),\n",
       " PosixPath('../data/receipt/納入済通知書送付票_カスレ_低解像度.pdf'),\n",
       " PosixPath('../data/receipt/領収書_歯科_sample.pdf'),\n",
       " PosixPath('../data/receipt/01_invoice_sample_01.pdf'),\n",
       " PosixPath('../data/receipt/02_receipt_sample.pdf'),\n",
       " PosixPath('../data/thesis/202303_ExDistilBERT_東芝.pdf'),\n",
       " PosixPath('../data/graphs/08_グラフ表混在_portlait_日本経済見通し_JRI_202507.pdf'),\n",
       " PosixPath('../data/graphs/07_グラフ表混在_landscape_日本経済展望_JRI_202507.pdf'),\n",
       " PosixPath('../data/insurance/tokyo_marine_yakkan_sample.pdf'),\n",
       " PosixPath('../data/insurance/nissei_miraino_katachi_sample.pdf')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = Path(\"../data/\")\n",
    "files_list = [f for f in base_dir.glob(\"**/*.pdf\")]\n",
    "files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826bc445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_results = run_baseline_timed(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebb3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデルを初期化中...\n",
      "モデルを初期化中...\n",
      "Qwen2.5VLモデルをダウンロード中...\n",
      "accelerateが利用可能です。device_mapを使用します。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:06<00:00,  1.26s/it]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qwen2.5VLモデルのダウンロード完了\n",
      "Qwen3VLモデルをダウンロード中...\n",
      "モデルのダウンロードが完了しました！\n",
      "初期化完了！\n",
      "Processing ../data/tables/04_要件定義書_表の中の表.pdf... (1/15)\n",
      "  Processing Qwen2.5VL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Qwen2.5VL completed in 354.15 seconds\n",
      "  File 1 completed\n",
      "\n",
      "Processing ../data/tables/03_要件定義書_各種テーブル.pdf... (2/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 526.37 seconds\n",
      "  File 2 completed\n",
      "\n",
      "Processing ../data/tegaki/20250915_業務日報.pdf... (3/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 40.44 seconds\n",
      "  File 3 completed\n",
      "\n",
      "Processing ../data/tegaki/0686240_ツミタス汎用_表.pdf... (4/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 107.12 seconds\n",
      "  File 4 completed\n",
      "\n",
      "Processing ../data/tegaki/0708742_JBEC・KEC_ミライト.pdf... (5/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 253.92 seconds\n",
      "  File 5 completed\n",
      "\n",
      "Processing ../data/others/縦書き_ルビあり.pdf... (6/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 252.36 seconds\n",
      "  File 6 completed\n",
      "\n",
      "Processing ../data/receipt/納入済通知書送付票_カスレ_低解像度.pdf... (7/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 253.70 seconds\n",
      "  File 7 completed\n",
      "\n",
      "Processing ../data/receipt/領収書_歯科_sample.pdf... (8/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 57.61 seconds\n",
      "  File 8 completed\n",
      "\n",
      "Processing ../data/receipt/01_invoice_sample_01.pdf... (9/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 81.25 seconds\n",
      "  File 9 completed\n",
      "\n",
      "Processing ../data/receipt/02_receipt_sample.pdf... (10/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 41.48 seconds\n",
      "  File 10 completed\n",
      "\n",
      "Processing ../data/thesis/202303_ExDistilBERT_東芝.pdf... (11/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 756.36 seconds\n",
      "  File 11 completed\n",
      "\n",
      "Processing ../data/graphs/08_グラフ表混在_portlait_日本経済見通し_JRI_202507.pdf... (12/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 165.23 seconds\n",
      "  File 12 completed\n",
      "\n",
      "Processing ../data/graphs/07_グラフ表混在_landscape_日本経済展望_JRI_202507.pdf... (13/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 267.20 seconds\n",
      "  File 13 completed\n",
      "\n",
      "Processing ../data/insurance/tokyo_marine_yakkan_sample.pdf... (14/15)\n",
      "  Processing Qwen2.5VL...\n",
      "    Qwen2.5VL completed in 1748.25 seconds\n",
      "  File 14 completed\n",
      "\n",
      "Processing ../data/insurance/nissei_miraino_katachi_sample.pdf... (15/15)\n",
      "  Processing Qwen2.5VL...\n"
     ]
    }
   ],
   "source": [
    "qwen_results = run_qwen_timed_with_datetime(files_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f22cd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
